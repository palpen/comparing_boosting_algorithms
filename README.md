# Comparing Boosting Algorithms (and Bagging)

An exploration of the performance and runtimes of AdaBoost, plain vanilla gradient boosting, XGBoost, and bagging using a census income dataset. I find that both XGBoost and plain gradient boosting performed better than both AdaBoost and bagging, but XGBoost had significantly shorter runtime.

Click [here](https://github.com/palpen/comparing_boosting_algorithms/blob/master/comparing_boosting_algorithms.ipynb) for the notebook.